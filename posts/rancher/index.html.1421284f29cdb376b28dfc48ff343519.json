{"head":{"title":"Rancher - How to","description":"I use the Rancher service for one of my projects. In order to share this cool discovery, I've made an article about \"How to deploy applications with Rancher\"","date":"2016-06-13T00:00:00.000Z","hero":"/assets/rancher.jpg","layout":"Post"},"body":"<h1 id=\"rancher-un-orchestrateur-petit-mais-puissant\"><a href=\"#rancher-un-orchestrateur-petit-mais-puissant\" class=\"phenomic-HeadingAnchor\">#</a>Rancher, un orchestrateur petit mais puissant</h1>\n<p>Mon expérience en tant que stagiaire chez Zenika m’a amené à utiliser\nRancher pour orchestrer mes conteneurs Docker. Je vous présente ici un\ncondensé de mon expérience avec cet outil, de son intérêt et de ses\npoints forts, par le biais d’un petit “How to“ sur comment déployer son\napplication ?</p>\n<p>On constate que de plus en plus d’utilisateurs Docker cherchent à\nmanipuler plus facilement leurs conteneurs et à mettre en place du\ndéploiement continu. L’environnement technique autour de la\nproblématique d’orchestration des modèles CaaS (Container as a Service)\nest très large et il est parfois difficile de s’y retrouver.</p>\n<h2 id=\"quen-est-t-il-de-rancher-\"><a href=\"#quen-est-t-il-de-rancher-\" class=\"phenomic-HeadingAnchor\">#</a>Qu’en est-t-il de Rancher ?</h2>\n<h3 id=\"késako\"><a href=\"#k%C3%A9sako\" class=\"phenomic-HeadingAnchor\">#</a>Késako</h3>\n<p>Rancher, projet open-source créé par la société Rancher Labs est un\noutil gratuit d’orchestration de conteneurs Docker. Il permet de\nfacilement déployer des conteneurs Docker sur des machines possédant\nDocker. Grâce à une configuration simple et complète, il permet de lier\nses conteneurs afin de composer des architectures de services aisément.\nIl peut déployer des containeurs sur des services cloud comme AWS,\nAzure, DigitalOcean mais aussi sur des machines personnalisées\npossédant Docker tout en s’appuyant sur docker-machine.</p>\n<h3 id=\"une-installation-assez-simple\"><a href=\"#une-installation-assez-simple\" class=\"phenomic-HeadingAnchor\">#</a>Une installation assez simple</h3>\n<p>Pour installer Rancher, à ce jour il suffit de posséder une machine\nlinux 64-bit avec au moins 1GB de mémoire vive.</p>\n<pre><code class=\"hljs language-bash\">$ sudo docker run <span class=\"hljs-_\">-d</span> --restart=always -p 8080:8080 rancher/server</code></pre>\n<p>Après quelques minutes d’installation, le server Rancher est disponible\nsur le port 8080 de votre machine (l’image contient une base MySQL, un\nZookeeper, Redis, et le serveur rancher). Vous pouvez vous y connecter\ncar l’accès est par défaut ouvert à tous. Par la suite,  vous pourrez\nactiver l’authentification,et ainsi facilement configurer des comptes\npour vos utilisateurs.</p>\n<p><img src=\"/assets/rancher/Environnement.png\" alt=\"Interface graphique de Rancher\"></p>\n<h3 id=\"déployer-une-application-simple-avec-rancher\"><a href=\"#d%C3%A9ployer-une-application-simple-avec-rancher\" class=\"phenomic-HeadingAnchor\">#</a>Déployer une application simple avec Rancher</h3>\n<p>Après l’IaaS, le SaaS, le PaaS, le DaaS et Patricia Kaas, voila\nmaintenant venue l’ère du Caas (Container as a Service). L’objectif\nici est de conteneuriser les services de son(ses) application(s) et de\nles faire interagir. Pour montrer simplement la mécanique de Rancher,\nj’ai choisi de vous présenter le déploiement d’une application web très\nsimple nommée whoami, disponible sur le Docker Hub (développé en Go\npar Emile Vauge).</p>\n<p>Pour ce faire, je vais vous expliquer  la méthode de création de\nservices par l’interface graphique. Sachez que l’on peut interagir\navec Rancher par l’intermédiaire d’un outil en ligne de commande\n(rancher-cli,encore très limité pour l’instant) ou d’API REST.</p>\n<h4 id=\"ajouter-des-hosts-sur-lesquels-déployer\"><a href=\"#ajouter-des-hosts-sur-lesquels-d%C3%A9ployer\" class=\"phenomic-HeadingAnchor\">#</a>Ajouter des hosts sur lesquels déployer</h4>\n<p>Dans un premier temps il faut définir des machines sur lesquelles\ndéployer votre application.</p>\n<p><img src=\"/assets/rancher/machine.png\" alt=\"Création de machines\"></p>\n<p>Rancher propose des connecteurs à plusieurs services cloud du web comme\nAmazon EC2, Azure, Digital Ocean, mais vous pouvez également ajouter\nn’importe quelle machine disposant de docker comme “host” Rancher\n(“Custom”).</p>\n<p>Pour l’exemple, j’ai ajouté deux machines au cluster nommées node1 et\nnode2, et j’ai ajouté l’hôte Rancher lui-même self\n(c’est possible mais non recommandé).</p>\n<p><img src=\"/assets/rancher/host.png\" alt=\"Hosts\"></p>\n<h4 id=\"créer-son-service\"><a href=\"#cr%C3%A9er-son-service\" class=\"phenomic-HeadingAnchor\">#</a>Créer son service</h4>\n<p>Il faut maintenant créer une stack pour accueillir notre service whoami.\nDans la logique Rancher, une stack est un ensemble de services.</p>\n<p><img src=\"/assets/rancher/stack.png\" alt=\"Stack\"></p>\n<p>On peut remarquer que pour l’ajout d’une stack, on peut importer un\nfichier <code>docker-compose.yml</code> et un fichier <code>rancher-compose.yml</code>.</p>\n<p>Le fichier docker-compose.yml définit la structure de la stack,\nl’ensemble de ses services ainsi que leurs configurations.\nCe fichier est natif de l’api Docker Compose.`</p>\n<p>Le fichier rancher-compose est un “add-on” au docker compose,\nil permet de configurer des paramètres Rancher comme la configuration\ndes loadbalancer (HA-Proxy) et la scalabilité horizontale des services.\nCes deux fichiers sont exportables à tout moment, cela peut-être très\npratique pour une réinstallation (par exemple, voici la\n<a href=\"https://drive.google.com/file/d/0B0NhGeba-vjZVnJldGRYUTBZaGs/view\">configuration de la stack</a>\nqui est installée dans cette partie).</p>\n<p>Une fois la stack créée en lui donnant uniquement un nom, il faut\najouter notre service whoami. Pour cela il suffit de cliquer sur\n“Add service” et de le définir comme cela.</p>\n<p><img src=\"/assets/rancher/whoami.png\" alt=\"Whoami example\"></p>\n<p>On remarque que seul le nom du service, l’image docker et le “port map”\nont été définis (ie: c’est un exemple simple, vous pouvez voir par les\nonglets du bas que la configuration peut être beaucoup plus poussée,\ngestion des volumes, du network du service, des HealthCheck).</p>\n<p>Après cette simple configuration, il suffira de cliquer sur “Create” et\ninformagiquement votre service sera déployé sur un host choisi par Cattle.</p>\n<p>Vous allez me dire, “qu’est ce que Cattle ?”, et vous aurez raison.\nCattle est l’orchestrateur par défaut utilisé par Rancher. Il est\nmaintenu par l’équipe de Rancher et le projet est open-source et\ndisponible sur Github.</p>\n<p>Sachez que Rancher fonctionne également avec Kubernetes, Swarm et\nMesos mais pour cet article, je me suis limité à l’utilisation de Cattle.</p>\n<h4 id=\"scaler-et-loadbalancer\"><a href=\"#scaler-et-loadbalancer\" class=\"phenomic-HeadingAnchor\">#</a>Scaler et Loadbalancer</h4>\n<p>Après quelques temps de démarrage, votre service whoami devrait être\ndisponible.</p>\n<p><img src=\"/assets/rancher/start.png\" alt=\"Start\"></p>\n<p>Si vous cliquez sur le “80”, vous devez accéder au service whoami.\nIl vous donnera plusieurs informations sur lui-même, notamment son nom.</p>\n<p>Le but maintenant est de scaler notre service, afin de le distribuer\nsur plusieurs machines.</p>\n<p>Dans le détail du service, on peut voir que la scale est actuellement\ndéfinie à 1. Il suffirait donc de l’augmenter ? Et bien non, le service\nque nous venons de définir occupe le port 80 de la machine. Il ne\npourrait donc pas être disponible plus d’une fois par machine. Et c’est\nlà l’une des problématiques des microservices :  l’allocation dynamique\nde port et la “connaissance” des services par le loadbalancer. Rancher\noffre une solution simple à ce problème, il ne faut plus réserver de\nport pour son application, le loadbalancer va connaître les services\npar l’orchestrateur.</p>\n<p>Il faut donc supprimer la configuration du port statique du service.</p>\n<p>Une fois le port libéré , il faut donc créer un loadbalancer qui\ndistribue la charge entre les instances de whoami. Dans la stack,\ncliquez sur “Add Load Balancer”</p>\n<p><img src=\"/assets/rancher/loadb.png\" alt=\"Load balancer\"></p>\n<p>Une fois le loadbalancer créé, on peut donc augmenter la scale de son\napplication sans avoir de problème d’allocation de port. Si vous cliquez\nle “80” du loadbalancer, vous devez atteindre votre service, et s’il\nest scalé, l’hostname devrait changer au refresh.</p>\n<p>A ce stade du déploiement, on peut se demander, ce qu’il en est de\nl’infrastructure des machines  créées plus tôt.</p>\n<p><img src=\"/assets/rancher/host2.png\" alt=\"Hosts\"></p>\n<p>Rancher a déployé les conteneurs docker de façon équilibrée entre les\ndifférentes machines. On peut définir nos propres règles de déploiement\npar l’utilisation de label sur les machines.</p>\n<p>Par exemple, on peut ajouter le label “name = frontend”, et pour chaque\nservice que l’on crée, définir si il peut démarrer ou non sur la machine\ndont le name est frontend.</p>\n<p>Sur chacun des conteneurs, rancher nous permet d’accéder à un shell et\nune vue des logs, ce qui est très pratique pour le débug.</p>\n<p>Certes cet exemple était simple, mais on peut facilement déployer des\narchitectures plus complexes grâce à Rancher, et c’est là tout son\nintérêt. Voici l’architecture des services de l’un des projets que j’ai\ndéployé grâce à lui.</p>\n<p><img src=\"/assets/rancher/microservices.png\" alt=\"Hosts\"></p>\n<h3 id=\"un-«-bluegreen-deployement-»--et-une-rolling-upgrade-en-5-minutes\"><a href=\"#un-%C2%AB-bluegreen-deployement-%C2%BB--et-une-rolling-upgrade-en-5-minutes\" class=\"phenomic-HeadingAnchor\">#</a>Un « blue/green deployement »  et une “rolling upgrade” en 5 minutes</h3>\n<p>Dans la plupart des cas, une mise en production est souvent un\npassage difficile pour le développeur. Les outils DevOps ont bien\névidemment permis de simplifier cette étape cruciale de la vie d’un\nprojet.</p>\n<p>Rancher permet d’utiliser plusieurs méthodes pour mettre à jour un\nservice déjà en production tout en garantissant la continuité des\nservices :</p>\n<h4 id=\"la-rolling-upgrade-remplacement-dun-service-par-un-autre\"><a href=\"#la-rolling-upgrade-remplacement-dun-service-par-un-autre\" class=\"phenomic-HeadingAnchor\">#</a>La rolling upgrade (remplacement d’un service par un autre)</h4>\n<p><img src=\"/assets/rancher/indiana.gif\" alt=\"Hosts\"></p>\n<h4 id=\"le-bluegreen-deployement\"><a href=\"#le-bluegreen-deployement\" class=\"phenomic-HeadingAnchor\">#</a>Le blue/green deployement</h4>\n<p>Ces deux méthodes ont été présentées par Christophe Furmaniak et\nYoucef Yekhlef (deux consultants architectes de Zenika) lors de leur\nintervention à de pendant la Devoxx 2016. Je ne peux que vous\nconseiller de la regarder :</p>\n<div style=\"position:relative;height:0;padding-bottom:56.25%\">\n<iframe src=\"https://www.youtube.com/embed/QFqt8xMTChY?ecver=2\" width=\"640\" height=\"360\" frameborder=\"0\" style=\"position:absolute;width:100%;height:100%;left:0\" allowfullscreen></iframe>\n</div>\n<h3 id=\"un-service-dns-et-network-overlay\"><a href=\"#un-service-dns-et-network-overlay\" class=\"phenomic-HeadingAnchor\">#</a>Un service DNS et Network overlay</h3>\n<p>Pour ceux qui ont déjà bien pratiqué Docker, faire communiquer deux\ncontaineurs entre eux sans avoir d’outil d’orchestration n’est pas très\naisé. Bien sûr, il y a la publication de port sur le Host, mais on\narrive vite aux limites. Rancher apporte nativement une fonctionnalité\nd’overlay network via un tunnel ipsec permettant à deux containers sur\ndeux machines différentes d’être sur le même réseau virtuel. Rancher va\nplus loin puisqu’il possède son service DNS dans lequel il enregistre\nchaque nouveau container qu’il crée. Cela a plusieurs avantages:</p>\n<ul>\n<li>Deux services d’une même Stack se connaissent par leur nom ;</li>\n<li>Un service peut connaître un service d’une autre stack par <code>nomService.nomStack</code>.</li>\n</ul>\n<h3 id=\"un-catalogue-qui-senrichit\"><a href=\"#un-catalogue-qui-senrichit\" class=\"phenomic-HeadingAnchor\">#</a>Un catalogue qui s’enrichit</h3>\n<p><img src=\"/assets/rancher/catalogue.png\" alt=\"Rancher catalogue\"></p>\n<p>Rancher possède son propre catalogue d’applications, ces applications\nsont sous la forme de groupes de stacks pré-configurées qui s’appuient\nsur les images du Docker Hub :</p>\n<ul>\n<li>La stack Elastic ;</li>\n<li>Janitor, un service basé sur docker-cleanup, pour nettoyer les images et conteneurs non-utilisés. ;</li>\n<li>Traefik, un load balancer développé en Go par Emile Vauge de la Zstartup Containous ;</li>\n<li>Gluster, un gestionnaire de volume partagé ;</li>\n<li>Odoo, le célèbre ERP open source ;</li>\n<li>etc.</li>\n</ul>\n<p>Il est aussi possible d’ajouter son propre\n<a href=\"http://docs.rancher.com/rancher/v1.5/en/catalog/\">catalogue de stacks d’entreprise</a></p>\n<p>Je vous ai présenté ici les principales features de Rancher,\nje ne peux que vous conseiller de le tester pour faire joujou avec vos\nconteneurs Docker. Cependant, la question qu’on peut encore se poser\naujourd’hui reste la suivante : Rancher ne restera-t-il qu’un joujou\npour orchestrer des services ? On sait déjà que des entreprises comme\nOrange et Sony commencent à l’utiliser pour des besoins interne\n(cf : Sony et le playstation Network <a href=\"https://www.youtube.com/watch?v=hwhxXwT6zlw\">https://www.youtube.com/watch?v=hwhxXwT6zlw</a>)</p>\n<p>N’hésitez surtout pas à partager vos expériences avec Rancher.</p>\n<p>Merci encore à Youcef Yekhlef, Christophe Furmaniak et à mon tuteur de\nstage Christophe Tardella pour l’aide apportée à la rédaction de cet article.</p>\n","__filename":"posts/rancher.md","__url":"/posts/rancher/","__resourceUrl":"/posts/rancher/index.html","__dataUrl":"/posts/rancher/index.html.1421284f29cdb376b28dfc48ff343519.json"}